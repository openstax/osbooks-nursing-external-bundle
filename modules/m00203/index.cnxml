<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Evaluation Strategies</title>
  <metadata xmlns:md="http://cnx.rice.edu/mdml">
    <md:title>Communication Strategies</md:title>
    <md:content-id>m00203</md:content-id>
    <md:uuid>6075a3bc-3af6-4542-abcf-f565e703cf14</md:uuid>
  </metadata>
  <content>
    <section class="learning-objectives" id="sect-00001">
    <title>Learning Outcomes</title>
    <para id="para-00001">By the end of this section, you should be able to:</para>
    <list list-type="bulleted" id="list-00001">
    <item>Describe an intervention evaluation plan for public health services for individuals, families, and groups.</item>
    <item>Utilize a systematic process to direct the evaluation of public health interventions.</item>
    <item>Evaluate outcomes of action plans and interventions, considering implications for practice.</item>
    </list>
    </section>
    <para id="para-00002">Evaluation of community programs occurs throughout implementation and at the conclusion of a program to improve processes and outcomes. The evaluation provides evidence for decisions regarding the program, such as whether the program should continue, if revisions are needed, or if the program should be discontinued. Additionally, evaluation may either be mandated by external funders, driven by a need to determine program effectiveness, or both (Centers for Disease Control and Prevention [CDC], 2012). The program team develops a plan for evaluation during the planning phases of community health programming, determining the evaluation methods before beginning intervention activities. Using a systematic process ensures all components of the program are evaluated in an evidence-based way. No matter the process and methods used, the program team evaluates whether goals and objectives of the program are met. If a health program fails to meet the goals and objectives or the community’s needs, the team should carefully consider the program’s future.</para>
       <section id="sect-00003">
    <title>Evaluation Planning for Public Health Programs</title>
    <para id="para-00003"><term id="term-00001">Program evaluation</term> is the ongoing, systematic collection, analysis, and use of data to examine program <term id="term-00002">efficacy</term>, <term id="term-00003">effectiveness</term>, and <term id="term-00004">efficiency</term> to make decisions about current and future health programs (CDC, 2012; Issel &amp; Wells, 2018). Efficacy is the “maximum potential effect under ideal conditions” (Issel &amp; Wells, 2018, p. 222). Ideal conditions are difficult to create in community health programs, so efficacy is rarely evaluated. Effectiveness is the community program’s ability to achieve the desired outcome in real-life settings (Issel &amp; Wells, 2018). It is usually measured using statistical data and comparisons to benchmarks. Efficiency occurs when the effect of program interventions, or outputs, are greater than the resources, or inputs, used to provide the intervention (Issel &amp; Wells, 2018). The program team plans for evaluation in order to:</para>
    <list list-type="bulleted" id="list-00002">
    <item>monitor progress toward program goals and objectives,</item>
    <item>decide if program activities and components are leading to the desired results,</item>
    <item>make comparisons among program participants and other populations,</item>
    <item>provide rationale for further funding and support,</item>
    <item>ensure continuous quality improvement,</item>
    <item>verify program maintenance and efficient use of resources,</item>
    <item>document accountability that the program is fulfilling its purpose and meeting goals, and</item>
    <item>justify sustaining, revising, or discontinuing the program (CDC, 2021).</item>
    </list>
    <para id="para-00004">As noted, the program team plans for evaluation during the program planning process and prior to implementing interventions. Steps to planning for program evaluation include the following:</para>
    <list list-type="enumerated" number-style="arabic" id="list-00003">
    <item>Identify individuals and groups to plan and assist with evaluation.</item>
    <item>Meet with the program team to determine how to evaluate the program.</item>
    <item>Examine evaluation types and processes used in the literature.</item>
    <item>Choose the type of evaluation to be used and a systematic process that aligns with evaluation needs and program goals.</item>
    <item>Determine what program goals and objectives will be measured, how they will be measured, who will be responsible for collecting data, and what resources are available.</item>
    <item>Write the program evaluation plan using the types of evaluation and chosen systematic process.</item>
    </list>
    <para id="para-00005">The program team determines which type of community health  program evaluation will be conducted. The most common types are <term id="term-00005">formative evaluation</term>, <term id="term-00006">process evaluation</term>, <term id="term-00007">outcome evaluation</term>, and <term id="term-00008">impact evaluations</term>. The choice of type depends upon program activities, organizational needs, funder requirements, and the program’s developmental stage.</para>
    <section id="sect-00004">
    <title>Formative Evaluation</title>
    <para id="para-00006">Formative evaluation occurs during program development to confirm that program interventions are feasible and appropriate (CDC, 2014). Most often, formative evaluation occurs during new program development or when an existing program is revised. Formative evaluation includes a community health needs assessment as discussed in <link document="m00187">Assessment, Analysis, and Diagnosis</link>.</para>
    </section>
    <section id="sect-00005">
    <title>Process Evaluation</title>
    <para id="para-00007">Process evaluation focuses on program implementation processes to determine if the program has been implemented efficiently and as planned. It occurs throughout program implementation, allowing for mid-program revisions and following the program to provide direction for future program improvement. As such, process evaluation should occur to some extent for all community health programs. During process evaluation, the program team describes the program’s inputs and outputs. <term class="no-emphasis" id="term-00009">Program inputs</term> are those things and resources required to carry out the program; examples are personnel number and experience, volunteers, informational and technological resources, financial resources and budget, physical location and resources, transportation needs, leadership, time, marketing needs, and other resources needed to complete activities (Issel &amp; Wells, 2018). <term class="no-emphasis" id="term-00010">Program outputs</term> are things accomplished using inputs. Examples of outputs are population reach; number of participants; intervention dose and amount; equipment or incentives distributed; partnerships developed; staff and volunteer hours worked; extent that the budget was followed; quality of information, technological, and physical resources; and staff, volunteer, and participant satisfaction (Issel &amp; Wells, 2018). Most often, the team describes inputs and outputs using qualitative data, but they may use some quantitative data. The program team explains what and how much was accomplished during the program and determines strengths, areas for improvement, and recommendations for ongoing and future program implementation.</para>
    </section>
    <section id="sect-00006">
    <title>Outcome Evaluation</title>
    <para id="para-00008">Outcome evaluation assesses the extent to which the program achieves its objectives within the target population and its effect on the target populations’ knowledge, attitudes, and behaviors (CDC, 2014). This is an evaluation of the SMART objectives developed during the program development planning stages (<link target-id="fig-00001" document="m00203"/>). <link document="m00192">Planning Health Promotion and Disease Prevention Interventions</link> guides the nurse in the development of <term class="no-emphasis" id="term-00011">SMART objectives</term>. Outcome evaluation should be completed for all community health programs regardless of developmental level. Typically, outcome evaluations are quantitative and include short-, medium-, and long-term measures of change. At times, the team may use qualitative data to provide support for quantitative results. It is recommended that process and outcome evaluation occur simultaneously because if a program objective is not met, it could be a result of implementation process issues (CDC, 2014).</para>
    <figure class="scaled-down" id="fig-00001">
    <media alt="A speaker at a podium next to an easel addresses a roomful of people. A chart with a bar graph and other written information sits on the easel.">
    <image mime-type="image/png" src="../../media/PH_Figure_20_03_002.jpg"/></media>
    <caption>During outcome evaluation, the team assesses the effectiveness of the SMART objectives on meeting their goals within the target population. (credit: “Maryland Rural Health Day Calvert County Health Department” by Anthony DePanise/Flickr, CC BY 2.0)</caption>
    </figure>
    </section>
    <section id="sect-00007">
    <title>Impact Evaluation</title>
    <para id="para-00009">Impact evaluation determines the degree to which the community health program has achieved its primary goal (CDC, 2014). It occurs during an existing program, if appropriate, and at the end of a program and most often uses data collected over the long term, including community health assessment data and benchmarks. Most impact evaluations are quantitative. For example, an evaluation might compare pre-program and post-program morbidity, mortality, and health behavior data for the target population and community as a whole.</para>
    <note class="theory-action" id="note-00001">
    <title>Types of Program Evaluation</title>
    <media alt="atoms_isotopes">
    <iframe width="560" height="315" src="https://openstax.org/r/programevaluation"/>
    </media>
    <para id="para-00010">Various program evaluation types are available to determine if a community health program has been effectively and efficiently implemented. This video describes formative, process, impact, and outcome evaluations.</para>
    <para id="para-00022">Watch the video, and then respond to the following questions.</para>
    <list list-type="enumerated" number-style="arabic" id="list-00004">
    <item>How does the nurse and program team determine which type of program evaluation should be used?</item>
    <item>What evaluation designs are used to conduct program outcome evaluations?</item>
    </list>
    </note>
    </section>
    </section>
    <section id="sect-00008">
    <title>Systematic Processes to Direct Program Evaluation</title>
    <para id="para-00011">The nurse in <term class="no-emphasis" id="term-00012">collaboration</term> with the program planning team chooses an evaluation framework or tool to guide evaluation planning. Frameworks and tools provide systematic, evidence-based resources to organize important program evaluation components. Commonly used frameworks and tools include the CDC Framework for Program Evaluation in Public Health (CDC, 1999), Public Health Ontario’s steps for evaluating health promotion programs (Ontario Agency for Health Protection and Promotion [OAHPP] et al., 2016), and <term class="no-emphasis" id="term-00013">logic models</term>.</para>
    <section id="sect-00009">
    <title>CDC’s Framework for Program Evaluation in Public Health</title>
    <para id="para-00012">The <term class="no-emphasis" id="term-00014">CDC Framework for Program Evaluation in Public Health</term> is commonly used to summarize elements of program evaluation to assign value and judge a community health program based on evidence. The program team assigns value related to program quality, cost-effectiveness, and significance of the health problem. The framework contains two elements: six steps of program evaluation and standards to assess the quality of evaluation (<link target-id="fig-00002" document="m00203"/>) (CDC, 1999). While the program team does not need to conduct the evaluation in a linear sequence, they must thoroughly address each step. <link target-id="table-00001" document="m00203"/> provides examples of activities that occur during each step of program evaluation.</para>
    <figure class="scaled-down" id="fig-00002">
    <media alt="The CDC’s Framework for Program Evaluation is presented as 4 circles nested inside each other. The outermost circle says Steps in Evaluation. The next circle shows the following steps connected by arrows: Engage stakeholders, Describe the program, Focus the evaluation design, Gather credible evidence, Justify conclusions, Ensure use and share lessons learned. The next circle says Standards for Evaluation. The innermost circle is divided into 4 quadrants that say Utility, Feasibility, Propriety, and Accuracy.">
    <image mime-type="image/png" src="../../media/PH_Figure_20_03_003.png"/></media>
    <caption>The Framework for Program Evaluation in Public Health is commonly used to evaluate public health programs. (See CDC, 1999; attribution: Copyright Rice University, OpenStax, under CC BY 4.0 license)</caption>
    </figure>
    <table class="vertically-tight alternate-shading full-width" id="table-00001">
    <tgroup cols="2">
    <colspec colnum="1" colname="c1" colwidth="1*"/>
    <colspec colnum="2" colname="c2" colwidth="2*"/>
    <thead>
    <row>
    <entry valign="top" align="left"><emphasis effect="bold"><span class="blue-text">Steps of Program Evaluation</span></emphasis></entry>
    <entry valign="top" align="left"><emphasis effect="bold"><span class="blue-text">Examples of Activities</span></emphasis></entry>
    </row>
    </thead>
    <tbody>
    <row>
    <entry valign="top" align="left">Engage interested parties</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00005">
    <item>Invite community members and partners identified during the community assessment and program planning process to assist with program evaluation</item>
    <item>Make a list of what evaluation data would be useful to each interested party and partner</item></list></entry>
    </row>
    <row>
    <entry valign="top" align="left">Describe the program</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00006">
    <item>Write the first portion of the evaluation plan, which includes program mission, objectives, activities, intended outcomes, and program maturity</item>
    <item>Create a logic model, if desired, that includes program inputs, activities, outputs, and short-, intermediate-, and long-term outcomes</item></list></entry>
    </row>
    <row>
    <entry valign="top" align="left">Focus on the evaluation design</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00007">
    <item>Choose the evaluation design (process, outcome, and/or impact evaluation), considering the program’s purpose and maturity</item></list></entry>
    </row>
    <row>
    <entry valign="top" align="left">Gather credible evidence</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00008">
    <item>Determine the quantity and quality of data to collect, using multiple data sources to increase the accuracy of evaluation results</item>
    <item>Prepare data collection methods, which could include surveys, interviews, focus groups, retrospective document reviews, and observation</item>
    <item>Collect data from participants, staff, volunteers, and other relevant parties, and use secondary data sources for benchmarking</item></list></entry>
    </row>
    <row>
    <entry valign="top" align="left">Justify conclusions</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00009">
    <item>Analyze and review results, comparing program objectives, benchmarks, literature, and previous implementations, if applicable</item>
    <item>Summarize strengths and areas for improvement of the program</item>
    <item>Meet with partners to review data and make conclusions regarding the program</item></list></entry>
    </row>
    <row>
    <entry valign="top" align="left">Ensure the use and share lessons learned</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00010">
    <item>Share results with program partners, and community</item></list></entry>
    </row>
    </tbody>
    </tgroup>
    <caption>Activities Completed During Program Evaluation  (See CDC, 1999.)</caption>
    </table>
    <para id="para-00013">The program team incorporates the standards of utility, feasibility, propriety, and accuracy throughout program evaluation. <term id="term-00015">Utility standards</term> include determining who needs evaluation information, what information they need, the evaluation’s purpose, and how the information will be used (CDC, 1999). <term id="term-00016">Feasibility standards</term> involve considering resources available to conduct program evaluation, including money, time, and effort (CDC, 1999). <term id="term-00017">Propriety standards</term> confirm that program evaluation is fair and ethical (CDC, 1999). <term id="term-00018">Accuracy standards</term> substantiate that program evaluation methods, data, and documentation are appropriate and contain accurate information (CDC, 1999). The CDC (2011) provides a <link url="https://openstax.org/r/cdcb">workbook</link> to guide program teams through the evaluation process.</para>
    </section>
    <section id="sect-00010">
    <title>Public Health Ontario’s Steps for Evaluating Health Promotion Programs</title>
    <para id="para-00014">Public Health Ontario (OAHPP et al., 2016), a scientific and technical public health organization in Ontario, Canada, recommends 10 systematic steps to evaluate health promotion programs (<link target-id="table-00002" document="m00203"/>). Similar to other public health evaluation frameworks, the program team conducts the first steps of program evaluation planning concurrently with program development. The program team engages interested parties, develops the program goals and objectives, determines the target population, creates program strategies and activities, and locates program resources. The organization recommends developing a logic model to represent the program to summarize its main components and to align evaluation questions with program activities (OAHPP et al., 2016). <link document="m00192">Planning Health Promotion and Disease Prevention Interventions</link> discusses using logic models in health program planning. Process and outcome evaluation measures should be used. The program team plans to gather data using quantitative and qualitative measures to have substantial information to determine program effectiveness and make decisions regarding health programs. The program team shares findings with interested parties to solicit recommendations and make program decisions. An <link url="https://openstax.org/r/publichealthontario">introductory workbook</link> (OAHPP et al., 2016) is available to assist the program team through evaluation planning and gathering, analyzing, and reporting program data.</para>
<table class="vertically-tight full-width" id="table-00002">
<tgroup cols="2">
<colspec colnum="1" colname="c1" colwidth="1*"/>
<colspec colnum="2" colname="c2" colwidth="2*"/>
<tbody>
<row>
<entry valign="middle" align="center" morerows="5"><emphasis effect="bold"><span class="blue-text">Planning</span></emphasis></entry>
<entry valign="top" align="left">Step 1: Clarify the program</entry>
</row>
<row>
<entry valign="top" align="left">Step 2: Engage interested parties</entry>
</row>
<row>
<entry valign="top" align="left">Step 3: Assess resources and evaluability</entry>
</row>
<row>
<entry valign="top" align="left">Step 4: Determine your evaluation questions</entry>
</row>
<row>
<entry valign="top" align="left">Step 5: Determine appropriate methods of measurement and procedures</entry>
</row>
<row>
<entry valign="top" align="left">Step 6: Develop an evaluation plan</entry>
</row>
<row>
  <entry valign="middle" align="center" morerows="1"><emphasis effect="bold"><span class="blue-text">Implementation</span></emphasis></entry>
<entry valign="top" align="left">Step 7: Collect data</entry>
</row>
<row>
<entry valign="top" align="left">Step 8: Process data and analyze results</entry>
</row>
<row>
  <entry valign="middle" align="center" morerows="1"><emphasis effect="bold"><span class="blue-text">Utilization</span></emphasis></entry>
<entry valign="top" align="left">Step 9: Interpret and disseminate the results</entry>
</row>
<row>
<entry valign="top" align="left">Step 10: Apply evaluation findings</entry>
</row>
<row>
<entry valign="top" align="left" namest="c1" nameend="c2">For more information, see <link url="https://openstax.org/r/publichealthontarioa">Evaluating health promotion programs: introductory workbook</link>.</entry>
</row>
</tbody>
</tgroup>
<caption>Public Health Ontario’s 10 Steps to Systematically Evaluate Public Health Programs</caption>
</table>
    </section>
    <section id="sect-00011">
    <title>Logic Models</title>
    <para id="para-00015"><term class="no-emphasis" id="term-00019">Logic models</term> are tools used to visually present the relationships among resources that are used to implement a program, the activities planned, and the intended results of a program (W. K. Kellogg Foundation, 2004). Logic models are also used to map evaluation questions and indicators. If the program team did not create a logic model during the program planning process, it is recommended that the program team create one to assist in evaluation efforts. <link document="m00192">Planning Health Promotion and Disease Prevention Interventions</link> describes how to create a health program logic model. After creating a logic model, the team can use it to decide on process and/or outcome evaluation methods and link evaluation questions to logic model components.</para>
    <note class="theory-action" id="note-00002">
    <title>Logic Models in Program Planning and Evaluation</title>
    <media alt="atoms_isotopes">
    <iframe width="560" height="315" src="https://openstax.org/r/logicmodelstheory"/>
    </media>
    <para id="para-00016">Logic models are used during program planning, implementation, and evaluation. This video demonstrates how to develop a logic model and provides an example using a parent training program.</para>
    <para id="para-00023">Watch the video, and then respond to the following questions.</para>
    <list list-type="enumerated" number-style="arabic" id="list-00011">
    <item>What are the components of a logic model?</item>
    <item>How does the nurse connect the logic model to program evaluation and evaluation methods?</item>
    <item>Using what you have learned regarding types of program evaluation, which components of the logic model align with process evaluation, which components align with outcome evaluation, and which components align with impact evaluation?</item>
    </list>
    </note>
    </section>
    </section>
    <section id="sect-00012">
    <title>Evaluating Outcomes of Action Plans and Interventions </title>
    <para id="para-00017">A community health program’s outcomes should always be evaluated to determine if program goals and objectives have been met. Data regarding program interventions and activities should be evaluated and analyzed individually and as a whole. The SMART objectives and logic model written during the planning phase, as discussed in <link document="m00192">Planning Health Promotion and Disease Prevention Interventions</link>, are used to develop evaluation questions and determine data collection techniques.</para>
    <para id="para-00018"><term class="no-emphasis" id="term-00020">Data collection</term> techniques include questionnaires to measure knowledge, attitudes, or behavior; observation; interviews; focus groups; and epidemiologic data. The team may collect data from participants, staff, volunteers, and community partners. Participants should always be evaluated to determine knowledge, attitude, or behavior changes. The team may collect pre-implementation or baseline data from epidemiological data, community health assessments, and participant surveys prior to program interventions.</para>
    <para id="para-00019">Short-term objectives are often measured immediately following program intervention. Intermediate objectives are measured within a few months following the program, usually within 3 to 6 months. Long-term objectives are usually measured at least one year following the program. The team evaluates impact using community health data. Most often, the nurse and program team use annual epidemiological data or community health assessment data, which is collected at minimum every three years. Benchmarks help determine the impact of programs. For example, in <link document="m00192">Planning Health Promotion and Disease Prevention Interventions</link>, the nurse and Kenton Hardin County Family Bike Program (KHCFBP) team determined evaluation questions and data techniques from the outcome and impact sections of the logic model. <link target-id="table-00003" document="m00203"/> describes the outcome evaluation of the program.</para>
    <table class="vertically-tight alternate-shading full-width" id="table-00003">
    <tgroup cols="3">
    <colspec colnum="1" colname="c1" colwidth="1*"/>
    <colspec colnum="2" colname="c2" colwidth="2*"/>
    <colspec colnum="3" colname="c3" colwidth="3*"/>
    <thead>
    <row>
    <entry valign="top" align="left"><emphasis effect="bold"><span class="blue-text">Outcome as Stated on the Logic Model</span></emphasis></entry>
    <entry valign="top" align="left"><emphasis effect="bold"><span class="blue-text">Evaluation Question</span></emphasis></entry>
    <entry valign="top" align="left"><emphasis effect="bold"><span class="blue-text">Data Collection Technique</span></emphasis></entry>
    </row>
    </thead>
    <tbody>
    <row>
    <entry valign="top" align="left">Short term—Increase participant bike safety knowledge post-program</entry>
    <entry valign="top" align="left">What was the effect of the KHCFBP on participants’ bike safety knowledge?</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00012">
    <item>Pre-survey: five questions to determine baseline bike safety knowledge</item>
    <item>Post-survey including the same questions at completion of activities to determine change in knowledge</item></list></entry>
    </row>
    <row>
    <entry valign="top" align="left">Short term—Increase participant bike helmet use 30 days post-program</entry>
    <entry valign="top" align="left">What was the effect of the KHCFBP on participants’ report of bike helmet use?</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00013">
    <item>Pre-survey: one Likert-scale question asking frequency of bike helmet use to determine baseline</item>
    <item>30 days post-survey: same question asking frequency of bike helmet use</item>
    <item>Pre-survey: one question asking if participant owned a bike helmet</item></list></entry>
    </row>
    <row>
    <entry valign="top" align="left">Short term—Increase participant biking frequency 30 days post-program</entry>
    <entry valign="top" align="left">What was the effect of the KHCFBP on participants’ report of bike riding?</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00014">
    <item>Pre-survey: questionnaire asking days per week, average time per day, and intensity of biking for leisure and commuting to determine baseline</item>
    <item>30-day post-survey: same questionnaire</item></list></entry>
    </row>
    <row>
    <entry valign="top" align="left">Long term—Increase incidence of biking in Hardin County over the next 5 years</entry>
    <entry valign="top" align="left">Did incidence of bike riding increase in Hardin County?</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00015">
    <item>2017 CHA data to determine community baseline</item>
    <item>2023 CHA data to be used for comparison</item>
    <item>Healthy People data to use for benchmarking</item></list></entry>
    </row>
    <row>
    <entry valign="top" align="left">Impact—Increase physical activity of Hardin County residents</entry>
    <entry valign="top" align="left">Did physical activity of Hardin County residents increase?</entry>
    <entry valign="top" align="left">
    <list list-type="bulleted" id="list-00016">
    <item>2017 CHA data to determine community baseline</item>
    <item>2023 CHA data to be used for comparison</item>
    <item>Healthy People data and National Physical Activity Guidelines to use for benchmarking</item></list></entry>
    </row>
    </tbody>
    </tgroup>
    <caption>KHCFBP Evaluation Questions and Data Collection Techniques (See Hunsicker, 2020.)</caption>
    </table>
    <para id="para-00020">The program team analyzes data after collection. Pre-implementation and post-implementation data are compared. Program evaluation data are also compared to similar program evaluations and national benchmarks. The program team uses this information to evaluate the program’s strengths and weaknesses, determines if it has achieved desired outcomes, and examines its efficacy, effectiveness, and efficiency. The program team develops recommendations regarding the program and shares findings and recommendations with community members and partners. Ongoing evaluation of community health programs is necessary to ensure program success, program continuation, and that community needs are being met.</para>
      </section>
    <section class="section-summary" id="sect-00013">
    <title>Chapter Summary</title>
    <para id="para-00021">Evaluation of community health programs occurs to improve processes of implementation and program outcomes, assist in decision-making regarding the program, and meet funder requirements. A systematic process is used to evaluate the efficacy, effectiveness, and efficiency of the program components and the program as a whole. Formative, process, outcome, and impact are types of program evaluation that may be conducted. The CDC’s Framework for Program Evaluation in Public Health, Public Health Ontario’s steps for evaluating health promotion programs, and logic models are common frameworks and tools used in community health program evaluation. These tools direct the program team to align goals and objectives with type of evaluation, evaluation question, and data collection technique. The evaluation results are shared to make decisions, revisions, and recommendations for the program.</para>
    </section>
    </content>
    <glossary>
    <definition id="def-00001"><term>accuracy standards</term> <meaning>benchmarks that substantiate that program evaluation methods, data, and documentation are appropriate and contain accurate information</meaning></definition>
    <definition id="def-00002"><term>effectiveness</term> <meaning>ability of a community program to achieve the desired outcome in real-life settings</meaning></definition>
    <definition id="def-00003"><term>efficacy</term> <meaning>maximum potential effect under ideal conditions</meaning></definition>
    <definition id="def-00004"><term>efficiency</term> <meaning>occurs when the effect of program interventions, or outputs, are greater than the resources, or inputs, used to provide the interventions</meaning></definition>
    <definition id="def-00005"><term>feasibility standards</term> <meaning>benchmarks involving the consideration of resources, which include money, time, and effort, that are available to conduct program evaluation</meaning></definition>
    <definition id="def-00006"><term>formative evaluation</term> <meaning>an assessment that occurs during program development to confirm that program interventions are feasible and appropriate</meaning></definition>
    <definition id="def-00007"><term>impact evaluation</term> <meaning>an assessment to determine the degree to which the community health program has achieved its primary goal</meaning></definition>
    <definition id="def-00008"><term>outcome evaluation</term> <meaning>an assessment of the extent to which the program achieves its objectives within the target population and the effect the program has on the target populations’ knowledge, attitudes, and behaviors</meaning></definition>
    <definition id="def-00009"><term>utility standards</term> <meaning>specifications for determining who needs evaluation information, what information is needed, the purpose of evaluation, and how the information will be used</meaning></definition>
    <definition id="def-00010"><term>process evaluation</term> <meaning>an assessment focused on program implementation processes in order to determine if the program has been implemented as planned and in the most efficient way</meaning></definition>
    <definition id="def-00011"><term>program evaluation</term> <meaning>ongoing, systematic collection, analysis, and use of data to examine program efficacy, effectiveness, and efficiency to make decisions about current and future health programs</meaning></definition>
    <definition id="def-00012"><term>propriety standards</term> <meaning>criteria used to confirm that program evaluation is fair and ethical</meaning></definition>
    </glossary>
</document>